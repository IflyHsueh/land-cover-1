{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys, os, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "highres_colors = [\n",
    "    \"#000000\",\n",
    "    \"#0000FF\",\n",
    "    \"#008000\",\n",
    "    \"#80FF80\",\n",
    "    \"#806060\",\n",
    "]\n",
    "highres_cmap = matplotlib.colors.ListedColormap(highres_colors)\n",
    "\n",
    "import fiona\n",
    "import fiona.transform\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "import shapely\n",
    "import shapely.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLCD_CLASSES = [\n",
    "    0, 11, 12, 21, 22, 23, 24, 31, 41, 42, 43, 51, 52, 71, 72, 73, 74, 81, 82, 90, 95, 255\n",
    "]\n",
    "NLCD_CLASSES_TO_IDX = defaultdict(lambda: 0, {cl:i for i,cl in enumerate(NLCD_CLASSES)})\n",
    "NLCD_CLASS_IDX = range(len(NLCD_CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def humansize(nbytes):\n",
    "    suffixes = ['B', 'KB', 'MB', 'GB', 'TB', 'PB']\n",
    "    i = 0\n",
    "    while nbytes >= 1024 and i < len(suffixes)-1:\n",
    "        nbytes /= 1024.\n",
    "        i += 1\n",
    "    f = ('%.2f' % nbytes).rstrip('0').rstrip('.')\n",
    "    return '%s %s' % (f, suffixes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nlcd_stats(data):\n",
    "    counts = []\n",
    "    for val in NLCD_CLASSES:\n",
    "        counts.append((data==val).sum())\n",
    "    return np.array(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lc_stats(data):\n",
    "    vals = [1, 2, 3, 4, 5, 6, 15]\n",
    "    counts = []\n",
    "    for val in vals:\n",
    "        counts.append((data==val).sum())\n",
    "    return np.array(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_string(n):\n",
    "    alphabet = list(\"abcdefghijklmnopqrstuvwxyz\".upper())\n",
    "    return ''.join(np.random.choice(alphabet, n, replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounds_intersection(bound0, bound1):\n",
    "    left0, bottom0, right0, top0 = bound0\n",
    "    left1, bottom1, right1, top1 = bound1\n",
    "    left, bottom, right, top = \\\n",
    "            max([left0, left1]), max([bottom0, bottom1]), \\\n",
    "            min([right0, right1]), min([top0, top1])\n",
    "    return (left, bottom, right, top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_to_old_map = {}\n",
    "f = open(\"data/2013_2014-to-2011_2012.csv\", \"r\")\n",
    "f.readline()\n",
    "lines = f.read().strip().split(\"\\n\")\n",
    "for line in lines:\n",
    "    parts = line.split(\",\")\n",
    "    new_to_old_map[parts[0]] = parts[1]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\n",
    "    \"de_1m_2013\", # 107 tiles\n",
    "    \"ny_1m_2013\", # 407 tiles\n",
    "    \"md_1m_2013\", # 691 tiles\n",
    "    \"pa_1m_2013\", # 2239 tiles\n",
    "    \"wv_1m_2014\", # 292 tiles\n",
    "    \"va_1m_2014\"  # 1238 tiles\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find data that we can sample from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of classes per tile\n",
    "f = open(\"data/resampled-lc_counts.csv\",\"r\")\n",
    "header = f.readline().strip().split(\",\")\n",
    "lines = f.read().strip().split(\"\\n\")\n",
    "fns = []\n",
    "counts = []\n",
    "for line in lines:\n",
    "    parts = line.split(\",\")\n",
    "    fn = parts[0]\n",
    "    count = np.array(list(map(int, parts[1:])))\n",
    "    fns.append(fn)\n",
    "    counts.append(count)\n",
    "f.close()\n",
    "fns = np.array(fns)\n",
    "counts = np.array(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These naip files have blacked out areas \n",
    "bad_fns = pd.read_csv(\"data/naip_num_zeros.csv\")\n",
    "bad_fns = bad_fns[bad_fns.num_zeros>0].naip_fn.tolist()\n",
    "bad_fns = set([\n",
    "    fn.replace(\"esri-naip\", \"resampled-lc\")[:-4] + \"_lc.tif\"\n",
    "    for fn in bad_fns\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~(counts[:,-1] > 0)\n",
    "good_fns = fns[mask]\n",
    "\n",
    "good_fns = [\n",
    "    fn for fn in good_fns\n",
    "    if fn not in bad_fns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_fns_counts = []\n",
    "good_fns_counts_map = {}\n",
    "for fn in good_fns:\n",
    "    count = counts[fns == fn]\n",
    "    good_fns_counts.append(count[0])\n",
    "    good_fns_counts_map[fn] = count[0]\n",
    "good_fns = np.array(good_fns)\n",
    "good_fns_counts = np.array(good_fns_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4975, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "good_fns_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_year_fns = defaultdict(list)\n",
    "for fn in good_fns:\n",
    "    parts = fn.split(\"/\")\n",
    "    state_year_fns[parts[9]].append(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "md_1m_2013 691\n",
      "de_1m_2013 107\n",
      "va_1m_2014 1238\n",
      "md_1m_2015 1\n",
      "wv_1m_2014 292\n",
      "ny_1m_2013 407\n",
      "pa_1m_2013 2239\n"
     ]
    }
   ],
   "source": [
    "for k, vs in state_year_fns.items():\n",
    "    print(k, len(vs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_year_expected_class_dist = {}\n",
    "for state in states:\n",
    "    counts = np.zeros((7), dtype=int)\n",
    "    for fn in state_year_fns[state]:\n",
    "        counts += good_fns_counts_map[fn]\n",
    "    probs = counts / counts.sum()\n",
    "    probs = probs[:-1]\n",
    "    state_year_expected_class_dist[state] = probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample 50 tiles per state to split into (train, val, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_test(fns, expected_dist):\n",
    "    counts = np.zeros((7), dtype=int)\n",
    "    for fn in fns:\n",
    "        counts += good_fns_counts_map[fn]\n",
    "    probs = counts / counts.sum()\n",
    "    probs = probs[:-1]\n",
    "    return stats.ks_2samp(probs, expected_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 20 5\n",
      "de_1m_2013 0.9999565148992584 0.9999565148992584 0.8095573106166531\n",
      "25 20 5\n",
      "ny_1m_2013 0.8095573106166531 0.8095573106166531 0.8095573106166531\n",
      "25 20 5\n",
      "md_1m_2013 0.9999565148992584 0.9999565148992584 0.9999565148992584\n",
      "25 20 5\n",
      "pa_1m_2013 0.8095573106166531 0.8095573106166531 0.9999565148992584\n",
      "25 20 5\n",
      "wv_1m_2014 0.8095573106166531 0.8095573106166531 0.8095573106166531\n",
      "25 20 5\n",
      "va_1m_2014 0.8095573106166531 0.9999565148992584 0.8095573106166531\n"
     ]
    }
   ],
   "source": [
    "num_total = 50\n",
    "num_train, num_test = 25, 20\n",
    "num_val = num_total - num_train - num_test\n",
    "\n",
    "state_year_splits = {}\n",
    "for state in states:\n",
    "    \n",
    "    fns = state_year_fns[state]\n",
    "    all_fns = np.random.choice(fns, size=num_total, replace=False)\n",
    "    np.random.shuffle(all_fns)\n",
    "    \n",
    "    train_fns, test_fns, val_fns = all_fns[:num_train], all_fns[num_train:(num_train+num_test)], all_fns[(num_train+num_test):]\n",
    "    print(len(train_fns), len(test_fns), len(val_fns))\n",
    "    \n",
    "    statistic, p1 = do_test(train_fns, state_year_expected_class_dist[state])\n",
    "    statistic, p2 = do_test(test_fns, state_year_expected_class_dist[state])\n",
    "    statistic, p3 = do_test(val_fns, state_year_expected_class_dist[state])\n",
    "    print(state, p1, p2, p3)\n",
    "    \n",
    "    state_year_splits[state] = (train_fns, test_fns, val_fns)\n",
    "    \n",
    "    f = open(\"splits/%s_train.txt\" % (state),\"w\")\n",
    "    f.write(\"\\n\".join(train_fns))\n",
    "    f.close()\n",
    "    \n",
    "    f = open(\"splits/%s_test.txt\" % (state),\"w\")\n",
    "    f.write(\"\\n\".join(test_fns))\n",
    "    f.close()\n",
    "    \n",
    "    f = open(\"splits/%s_val.txt\" % (state),\"w\")\n",
    "    f.write(\"\\n\".join(val_fns))\n",
    "    f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

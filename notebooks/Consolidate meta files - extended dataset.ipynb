{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_to_old_map = {}\n",
    "f = open(\"../data/2013-2014_to_2011-2012.csv\", \"r\")\n",
    "f.readline()\n",
    "lines = f.read().strip().split(\"\\n\")\n",
    "for line in lines:\n",
    "    parts = line.split(\",\")\n",
    "    u = os.path.basename(parts[0])[:-4] + \"_lc.tif\"\n",
    "    v = os.path.basename(parts[1])[:-4] + \"_lc.tif\"\n",
    "    new_to_old_map[u] = v\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\n",
    "    \"de_1m_2013\", # 107 tiles\n",
    "    \"ny_1m_2013\", # 407 tiles\n",
    "    \"md_1m_2013\", # 691 tiles\n",
    "    \"pa_1m_2013\", # 2239 tiles\n",
    "    \"wv_1m_2014\", # 292 tiles\n",
    "    \"va_1m_2014\"  # 1238 tiles\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_mapping = {}\n",
    "for state in states:\n",
    "    for ds in [\"val\",\"test\",\"extended-train\"]:\n",
    "        extended_ds = ds if ds.startswith(\"extended\") else \"extended-%s\" % (ds)\n",
    "        \n",
    "        f = open(\"../splits/%s_%s.txt\" % (state, ds),\"r\")\n",
    "        fns = [\n",
    "            os.path.basename(fn)\n",
    "            for fn in f.read().strip().split(\"\\n\")\n",
    "        ]\n",
    "        f.close()\n",
    "\n",
    "        f = open(\"../../data/%s_%s_tiles.csv\" % (state, extended_ds), \"w\")\n",
    "        f.write(\"id,naip-new_fn,naip-old_fn,lc_fn,nlcd_fn,landsat-leaf-on_fn,landsat-leaf-off_fn,buildings_fn\\n\")\n",
    "        for i, lc_fn in enumerate(fns):\n",
    "            \n",
    "            base_fn = \"_\".join(os.path.basename(lc_fn).split(\"_\")[:-2])\n",
    "            f.write(\"%d,%s,%s,%s,%s,%s,%s,%s\\n\" % (\n",
    "                i,\n",
    "                \"%s_%s_tiles/%s\" % (state, extended_ds, base_fn + \"_naip-new.tif\"),\n",
    "                \"%s_%s_tiles/%s\" % (state, extended_ds, base_fn + \"_naip-old.tif\"),\n",
    "                \"%s_%s_tiles/%s\" % (state, extended_ds, base_fn + \"_lc.tif\"),\n",
    "                \"%s_%s_tiles/%s\" % (state, extended_ds, base_fn + \"_nlcd.tif\"),\n",
    "                \"%s_%s_tiles/%s\" % (state, extended_ds, base_fn + \"_landsat-leaf-on.tif\"),\n",
    "                \"%s_%s_tiles/%s\" % (state, extended_ds, base_fn + \"_landsat-leaf-off.tif\"),\n",
    "                \"%s_%s_tiles/%s\" % (state, extended_ds, base_fn + \"_buildings.tif\")\n",
    "            ))\n",
    "            fn_mapping[(state,extended_ds,base_fn)] = i\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"../../data/\"\n",
    "for state in states:\n",
    "    for ds in [\"val\",\"test\",\"extended-train\"]:\n",
    "        extended_ds = ds if ds.startswith(\"extended\") else \"extended-%s\" % (ds)\n",
    "        \n",
    "        df = pd.read_csv(\"../../data/%s_%s_tiles.csv\" % (state, extended_ds))\n",
    "\n",
    "        for column in df.columns:\n",
    "            if \"_fn\" in column:\n",
    "                for fn in df[column].values:\n",
    "                    assert os.path.exists(os.path.join(BASE_DIR, fn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: run below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LC_VALS = [1, 2, 3, 4, 5, 6, 15]\n",
    "NLCD_VALS = [0, 11, 12, 21, 22, 23, 24, 31, 41, 42, 43, 51, 52, 71, 72, 73, 74, 81, 82, 90, 95, 255]\n",
    "\n",
    "LC_HEADER_STRING = ','.join([\n",
    "    \"lc_class_%d_count\" % (val)\n",
    "    for val in LC_VALS\n",
    "])\n",
    "NLCD_HEADER_STRING = ','.join([\n",
    "    \"nlcd_class_%d_count\" % (val)\n",
    "    for val in NLCD_VALS\n",
    "])\n",
    "\n",
    "for state in states:\n",
    "    for ds in [\"val\",\"extended-train\"]:\n",
    "        extended_ds = ds if ds.startswith(\"extended\") else \"extended-%s\" % (ds)\n",
    "        \n",
    "        f = open(\"../splits/%s_%s_metadata.csv\" % (state, extended_ds),\"r\")\n",
    "        lines = [\n",
    "            line.strip().split(\",\")\n",
    "            for line in f.read().strip().split(\"\\n\")\n",
    "        ]\n",
    "        f.close()\n",
    "\n",
    "        \n",
    "        f = open(\"../../data/%s_%s_patches.csv\" % (state, extended_ds), \"w\")\n",
    "        f.write(\"patch_id,patch_fn,tile_id,x_coord,y_coord,size,%s,%s\\n\" % (LC_HEADER_STRING, NLCD_HEADER_STRING))\n",
    "        for i, row in enumerate(lines):\n",
    "            patch_fn = \"%s_%s_patches/%s\" % (state, extended_ds, os.path.basename(row[0]))\n",
    "            base_fn = row[1]\n",
    "            \n",
    "            tile_id = fn_mapping[(state,extended_ds,base_fn)]\n",
    "            x_coord = int(row[2])\n",
    "            y_coord = int(row[3])\n",
    "            size = 240\n",
    "            remainder = row[4:]\n",
    "            \n",
    "            f.write(\"%d,%s,%d,%d,%d,%d,%s\\n\" % (\n",
    "                i,\n",
    "                patch_fn,\n",
    "                tile_id,\n",
    "                x_coord,\n",
    "                y_coord,\n",
    "                size,\n",
    "                ','.join(remainder)\n",
    "            ))\n",
    "        \n",
    "        f.close()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "    for ds in [\"val\",\"extended-train\"]:\n",
    "        extended_ds = ds if ds.startswith(\"extended\") else \"extended-%s\" % (ds)\n",
    "        \n",
    "        f = open(\"../splits/%s_%s_shapes.txt\" % (state, extended_ds),\"r\")\n",
    "        lines = f.read().strip().split(\"\\n\")\n",
    "        f.close()\n",
    "        print(len(lines))\n",
    "        \n",
    "        geojson = {\n",
    "            \"type\": \"FeatureCollection\",\n",
    "            \"crs\": { \"type\": \"name\", \"properties\": { \"name\": \"urn:ogc:def:crs:OGC:1.3:CRS84\" } },\n",
    "            \"features\": [\n",
    "                { \"type\": \"Feature\", \"properties\": { \"patch_id\": i}, \"geometry\": json.loads(line)}\n",
    "                for i, line in enumerate(lines)\n",
    "            ]\n",
    "        }\n",
    "        \n",
    "        f = open(\"../../data/%s_%s_patches.geojson\" % (state, extended_ds), \"w\")\n",
    "        f.write(json.dumps(geojson))\n",
    "        f.close()\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

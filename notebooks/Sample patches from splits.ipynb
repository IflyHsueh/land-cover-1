{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys, os, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "highres_colors = [\n",
    "    \"#000000\",\n",
    "    \"#0000FF\",\n",
    "    \"#008000\",\n",
    "    \"#80FF80\",\n",
    "    \"#806060\",\n",
    "]\n",
    "highres_cmap = matplotlib.colors.ListedColormap(highres_colors)\n",
    "\n",
    "import fiona\n",
    "import fiona.transform\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "import shapely\n",
    "import shapely.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLCD_CLASSES = [\n",
    "    0, 11, 12, 21, 22, 23, 24, 31, 41, 42, 43, 51, 52, 71, 72, 73, 74, 81, 82, 90, 95, 255\n",
    "]\n",
    "NLCD_CLASSES_TO_IDX = defaultdict(lambda: 0, {cl:i for i,cl in enumerate(NLCD_CLASSES)})\n",
    "NLCD_CLASS_IDX = range(len(NLCD_CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def humansize(nbytes):\n",
    "    suffixes = ['B', 'KB', 'MB', 'GB', 'TB', 'PB']\n",
    "    i = 0\n",
    "    while nbytes >= 1024 and i < len(suffixes)-1:\n",
    "        nbytes /= 1024.\n",
    "        i += 1\n",
    "    f = ('%.2f' % nbytes).rstrip('0').rstrip('.')\n",
    "    return '%s %s' % (f, suffixes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nlcd_stats(data):\n",
    "    counts = []\n",
    "    for val in NLCD_CLASSES:\n",
    "        counts.append((data==val).sum())\n",
    "    return np.array(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lc_stats(data):\n",
    "    vals = [1, 2, 3, 4, 5, 6, 15]\n",
    "    counts = []\n",
    "    for val in vals:\n",
    "        counts.append((data==val).sum())\n",
    "    return np.array(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_string(n):\n",
    "    alphabet = list(\"abcdefghijklmnopqrstuvwxyz\".upper())\n",
    "    return ''.join(np.random.choice(alphabet, n, replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounds_intersection(bound0, bound1):\n",
    "    left0, bottom0, right0, top0 = bound0\n",
    "    left1, bottom1, right1, top1 = bound1\n",
    "    left, bottom, right, top = \\\n",
    "            max([left0, left1]), max([bottom0, bottom1]), \\\n",
    "            min([right0, right1]), min([top0, top1])\n",
    "    return (left, bottom, right, top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_to_old_map = {}\n",
    "f = open(\"data/2013_2014-to-2011_2012.csv\", \"r\")\n",
    "f.readline()\n",
    "lines = f.read().strip().split(\"\\n\")\n",
    "for line in lines:\n",
    "    parts = line.split(\",\")\n",
    "    new_to_old_map[parts[0]] = parts[1]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\n",
    "    \"de_1m_2013\", # 107 tiles\n",
    "    \"ny_1m_2013\", # 407 tiles\n",
    "    \"md_1m_2013\", # 691 tiles\n",
    "    \"pa_1m_2013\", # 2239 tiles\n",
    "    \"wv_1m_2014\", # 292 tiles\n",
    "    \"va_1m_2014\"  # 1238 tiles\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample patches from the train and val files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples 15000\n",
      "Number of samples_per_tile that will give complete coverage 850.6944444444445\n",
      "Expected fraction of each tile that will be sampled 0.5877551020408164\n",
      "Size of sampled data 8.05 GB\n"
     ]
    }
   ],
   "source": [
    "num_tiles = 25\n",
    "samples_per_tile = 500\n",
    "sample_size = 240\n",
    "num_channels = 6\n",
    "num_bytes_per_channel = 1\n",
    "average_tile_size = 7000\n",
    "\n",
    "print(\"Number of samples\", num_tiles * samples_per_tile)\n",
    "print(\"Number of samples_per_tile that will give complete coverage\", (average_tile_size/sample_size) * (average_tile_size/sample_size))\n",
    "print(\"Expected fraction of each tile that will be sampled\", (samples_per_tile * (sample_size*sample_size)) / (average_tile_size*average_tile_size))\n",
    "print(\"Size of sampled data\", humansize(num_tiles * samples_per_tile * (sample_size*sample_size) * num_channels * num_bytes_per_channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(fns, state, output_dir):\n",
    "    \n",
    "    patch_fns = []\n",
    "    patch_metadata = []\n",
    "    patch_shapes = []\n",
    "\n",
    "    for i, lc_fn in enumerate(fns):\n",
    "        print(i, len(fns))\n",
    "\n",
    "        new_naip_fn = lc_fn.replace(\"resampled-lc\", \"esri-naip\")[:-7] + \".mrf\"\n",
    "        old_naip_fn = new_to_old_map[new_naip_fn]\n",
    "        nlcd_fn = old_naip_fn.replace(\"esri-naip\", \"resampled-nlcd\")[:-4] + \"_nlcd.tif\"\n",
    "\n",
    "        naip_f = rasterio.open(new_naip_fn, \"r\")\n",
    "        crs = naip_f.crs[\"init\"]\n",
    "        naip_bounds = naip_f.bounds\n",
    "\n",
    "        lc_f = rasterio.open(lc_fn, \"r\")\n",
    "        assert lc_f.crs[\"init\"] == crs\n",
    "        lc_bounds = lc_f.bounds\n",
    "\n",
    "        nlcd_f = rasterio.open(nlcd_fn, \"r\")\n",
    "        assert nlcd_f.crs[\"init\"] == crs\n",
    "        nlcd_bounds = nlcd_f.bounds\n",
    "\n",
    "        bounds = bounds_intersection(bounds_intersection(naip_bounds, lc_bounds), nlcd_bounds)\n",
    "        left, bottom, right, top = bounds\n",
    "        geom = shapely.geometry.mapping(shapely.geometry.box(left, bottom, right, top, ccw=True))\n",
    "                \n",
    "        naip_data, _ = rasterio.mask.mask(naip_f, [geom], crop=True)\n",
    "        #naip_data = np.rollaxis(naip_data, 0, 3)\n",
    "        naip_f.close()\n",
    "        lc_data, _ = rasterio.mask.mask(lc_f, [geom], crop=True)\n",
    "        #lc_data = np.squeeze(lc_data)\n",
    "        lc_f.close()\n",
    "        nlcd_data, _ = rasterio.mask.mask(nlcd_f, [geom], crop=True)\n",
    "        #nlcd_data = np.vectorize(NLCD_CLASSES_TO_IDX.__getitem__)(nlcd_data).astype(np.uint8)\n",
    "        nlcd_f.close()\n",
    "\n",
    "        geom = fiona.transform.transform_geom(crs,'epsg:4326', geom)\n",
    "        \n",
    "        #print(naip_fn, naip_data.shape, naip_data.dtype)\n",
    "        #print(nlcd_fn, nlcd_data.shape, nlcd_data.dtype)\n",
    "        #print(lc_fn, lc_data.shape, lc_data.dtype)\n",
    "\n",
    "        _, height, width = naip_data.shape\n",
    "\n",
    "        for j in range(samples_per_tile):\n",
    "\n",
    "            y = np.random.randint(0, height-sample_size)\n",
    "            x = np.random.randint(0, width-sample_size)\n",
    "\n",
    "            merged = np.concatenate([\n",
    "                naip_data[:, y:y+sample_size, x:x+sample_size],\n",
    "                lc_data[:, y:y+sample_size, x:x+sample_size],\n",
    "                nlcd_data[:, y:y+sample_size, x:x+sample_size],\n",
    "            ])\n",
    "\n",
    "            lc_string = ','.join(map(str,get_lc_stats(merged[4,:,:])))\n",
    "            nlcd_string = ','.join(map(str,get_nlcd_stats(merged[5:,:])))\n",
    "            \n",
    "            \n",
    "            left, bottom, right, top\n",
    "            \n",
    "            t_left = left + x\n",
    "            t_right = left + x + sample_size\n",
    "            t_top = top - y\n",
    "            t_bottom = top - y - sample_size\n",
    "            t_geom = shapely.geometry.mapping(shapely.geometry.box(t_left, t_bottom, t_right, t_top, ccw=True))\n",
    "            t_geom = fiona.transform.transform_geom(crs, 'epsg:4326', t_geom)\n",
    "\n",
    "            output_fn = \"%s-%s-%d.npy\" % (\n",
    "                state,\n",
    "                os.path.basename(new_naip_fn)[:-4],\n",
    "                j\n",
    "            )\n",
    "\n",
    "            np.save(os.path.join(output_dir, output_fn), merged[np.newaxis].data)\n",
    "            patch_fns.append(os.path.join(output_dir, output_fn))\n",
    "            patch_metadata.append((\n",
    "                new_naip_fn,\n",
    "                x, y,\n",
    "                lc_string,\n",
    "                nlcd_string\n",
    "            ))\n",
    "            patch_shapes.append(json.dumps(t_geom))\n",
    "    \n",
    "    return patch_fns, patch_metadata, patch_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de_1m_2013 train\n",
      "0 25\n",
      "1 25\n",
      "2 25\n",
      "3 25\n",
      "4 25\n",
      "5 25\n",
      "6 25\n",
      "7 25\n",
      "8 25\n",
      "9 25\n",
      "10 25\n",
      "11 25\n",
      "12 25\n",
      "13 25\n",
      "14 25\n",
      "15 25\n",
      "16 25\n",
      "17 25\n",
      "18 25\n",
      "19 25\n",
      "20 25\n",
      "21 25\n",
      "22 25\n",
      "23 25\n",
      "24 25\n",
      "de_1m_2013 val\n",
      "0 5\n",
      "1 5\n",
      "2 5\n",
      "3 5\n",
      "4 5\n",
      "ny_1m_2013 train\n",
      "0 25\n",
      "1 25\n",
      "2 25\n",
      "3 25\n",
      "4 25\n",
      "5 25\n",
      "6 25\n",
      "7 25\n",
      "8 25\n",
      "9 25\n",
      "10 25\n",
      "11 25\n",
      "12 25\n",
      "13 25\n",
      "14 25\n",
      "15 25\n",
      "16 25\n",
      "17 25\n",
      "18 25\n",
      "19 25\n",
      "20 25\n",
      "21 25\n",
      "22 25\n",
      "23 25\n",
      "24 25\n",
      "ny_1m_2013 val\n",
      "0 5\n",
      "1 5\n",
      "2 5\n",
      "3 5\n",
      "4 5\n",
      "md_1m_2013 train\n",
      "0 25\n",
      "1 25\n",
      "2 25\n",
      "3 25\n",
      "4 25\n",
      "5 25\n",
      "6 25\n",
      "7 25\n",
      "8 25\n",
      "9 25\n",
      "10 25\n",
      "11 25\n",
      "12 25\n",
      "13 25\n",
      "14 25\n",
      "15 25\n",
      "16 25\n",
      "17 25\n",
      "18 25\n",
      "19 25\n",
      "20 25\n",
      "21 25\n",
      "22 25\n",
      "23 25\n",
      "24 25\n",
      "md_1m_2013 val\n",
      "0 5\n",
      "1 5\n",
      "2 5\n",
      "3 5\n",
      "4 5\n",
      "pa_1m_2013 train\n",
      "0 25\n",
      "1 25\n",
      "2 25\n",
      "3 25\n",
      "4 25\n",
      "5 25\n",
      "6 25\n",
      "7 25\n",
      "8 25\n",
      "9 25\n",
      "10 25\n",
      "11 25\n",
      "12 25\n",
      "13 25\n",
      "14 25\n",
      "15 25\n",
      "16 25\n",
      "17 25\n",
      "18 25\n",
      "19 25\n",
      "20 25\n",
      "21 25\n",
      "22 25\n",
      "23 25\n",
      "24 25\n",
      "pa_1m_2013 val\n",
      "0 5\n",
      "1 5\n",
      "2 5\n",
      "3 5\n",
      "4 5\n",
      "wv_1m_2014 train\n",
      "0 25\n",
      "1 25\n",
      "2 25\n",
      "3 25\n",
      "4 25\n",
      "5 25\n",
      "6 25\n",
      "7 25\n",
      "8 25\n",
      "9 25\n",
      "10 25\n",
      "11 25\n",
      "12 25\n",
      "13 25\n",
      "14 25\n",
      "15 25\n",
      "16 25\n",
      "17 25\n",
      "18 25\n",
      "19 25\n",
      "20 25\n",
      "21 25\n",
      "22 25\n",
      "23 25\n",
      "24 25\n",
      "wv_1m_2014 val\n",
      "0 5\n",
      "1 5\n",
      "2 5\n",
      "3 5\n",
      "4 5\n",
      "va_1m_2014 train\n",
      "0 25\n",
      "1 25\n",
      "2 25\n",
      "3 25\n",
      "4 25\n",
      "5 25\n",
      "6 25\n",
      "7 25\n",
      "8 25\n",
      "9 25\n",
      "10 25\n",
      "11 25\n",
      "12 25\n",
      "13 25\n",
      "14 25\n",
      "15 25\n",
      "16 25\n",
      "17 25\n",
      "18 25\n",
      "19 25\n",
      "20 25\n",
      "21 25\n",
      "22 25\n",
      "23 25\n",
      "24 25\n",
      "va_1m_2014 val\n",
      "0 5\n",
      "1 5\n",
      "2 5\n",
      "3 5\n",
      "4 5\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "    for ds in [\"train\", \"val\"]:\n",
    "        print(state, ds)\n",
    "        output_dir = \"/mnt/blobfuse/cnn-minibatches/cvpr_splits/%s_%s/\" % (state, ds)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        f = open(\"splits/%s_%s.txt\" % (state, ds),\"r\")\n",
    "        fns = f.read().strip().split(\"\\n\")\n",
    "        f.close()\n",
    "\n",
    "        patch_fns, patch_metadata, patch_shapes = make_dataset(fns, state, output_dir)\n",
    "        \n",
    "        f = open(\"splits/%s_%s_metadata.csv\" % (state, ds), \"w\")\n",
    "        for i in range(len(patch_fns)):\n",
    "            f.write(\"%s,%s,%d,%d,%s,%s\\n\" % (\n",
    "                patch_fns[i],\n",
    "                *patch_metadata[i]\n",
    "            ))\n",
    "        f.close()\n",
    "        \n",
    "        f = open(\"splits/%s_%s_patches.txt\" % (state, ds), \"w\")\n",
    "        f.write(\"\\n\".join(patch_fns))\n",
    "        f.close()\n",
    "        \n",
    "        f = open(\"splits/%s_%s_shapes.txt\" % (state, ds), \"w\")\n",
    "        f.write(\"\\n\".join(patch_shapes))\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

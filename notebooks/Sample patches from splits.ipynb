{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys, os, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "highres_colors = [\n",
    "    \"#000000\",\n",
    "    \"#0000FF\",\n",
    "    \"#008000\",\n",
    "    \"#80FF80\",\n",
    "    \"#806060\",\n",
    "]\n",
    "highres_cmap = matplotlib.colors.ListedColormap(highres_colors)\n",
    "\n",
    "import fiona\n",
    "import fiona.transform\n",
    "import rasterio\n",
    "import rasterio.mask\n",
    "import shapely\n",
    "import shapely.geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NLCD_CLASSES = [\n",
    "    0, 11, 12, 21, 22, 23, 24, 31, 41, 42, 43, 51, 52, 71, 72, 73, 74, 81, 82, 90, 95, 255\n",
    "]\n",
    "NLCD_CLASSES_TO_IDX = defaultdict(lambda: 0, {cl:i for i,cl in enumerate(NLCD_CLASSES)})\n",
    "NLCD_CLASS_IDX = range(len(NLCD_CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def humansize(nbytes):\n",
    "    suffixes = ['B', 'KB', 'MB', 'GB', 'TB', 'PB']\n",
    "    i = 0\n",
    "    while nbytes >= 1024 and i < len(suffixes)-1:\n",
    "        nbytes /= 1024.\n",
    "        i += 1\n",
    "    f = ('%.2f' % nbytes).rstrip('0').rstrip('.')\n",
    "    return '%s %s' % (f, suffixes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nlcd_stats(data):\n",
    "    counts = []\n",
    "    for val in NLCD_CLASSES:\n",
    "        counts.append((data==val).sum())\n",
    "    return np.array(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lc_stats(data):\n",
    "    vals = [1, 2, 3, 4, 5, 6, 15]\n",
    "    counts = []\n",
    "    for val in vals:\n",
    "        counts.append((data==val).sum())\n",
    "    return np.array(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_string(n):\n",
    "    alphabet = list(\"abcdefghijklmnopqrstuvwxyz\".upper())\n",
    "    return ''.join(np.random.choice(alphabet, n, replace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bounds_intersection(bound0, bound1):\n",
    "    left0, bottom0, right0, top0 = bound0\n",
    "    left1, bottom1, right1, top1 = bound1\n",
    "    left, bottom, right, top = \\\n",
    "            max([left0, left1]), max([bottom0, bottom1]), \\\n",
    "            min([right0, right1]), min([top0, top1])\n",
    "    return (left, bottom, right, top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_to_old_map = {}\n",
    "f = open(\"../data/2013-2014_to_2011-2012.csv\", \"r\")\n",
    "f.readline()\n",
    "lines = f.read().strip().split(\"\\n\")\n",
    "for line in lines:\n",
    "    parts = line.split(\",\")\n",
    "    new_to_old_map[parts[0]] = parts[1]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = [\n",
    "    \"de_1m_2013\", # 107 tiles\n",
    "    \"ny_1m_2013\", # 407 tiles\n",
    "    \"md_1m_2013\", # 691 tiles\n",
    "    \"pa_1m_2013\", # 2239 tiles\n",
    "    \"wv_1m_2014\", # 292 tiles\n",
    "    \"va_1m_2014\"  # 1238 tiles\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample patches from the train and val files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples 5250\n",
      "Number of samples_per_tile that will give complete coverage 747.6806640625\n",
      "Expected fraction of each tile that will be sampled 0.0668734693877551\n",
      "Size of sampled data 223.02 GB\n"
     ]
    }
   ],
   "source": [
    "num_tiles = 105\n",
    "samples_per_tile = 50\n",
    "sample_size = 256\n",
    "num_channels = 29\n",
    "num_bytes_per_channel = 1\n",
    "average_tile_size = 7000\n",
    "\n",
    "print(\"Number of samples\", num_tiles * samples_per_tile)\n",
    "print(\"Number of samples_per_tile that will give complete coverage\", (average_tile_size/sample_size) * (average_tile_size/sample_size))\n",
    "print(\"Expected fraction of each tile that will be sampled\", (samples_per_tile * (sample_size*sample_size)) / (average_tile_size*average_tile_size))\n",
    "print(\"Size of sampled data\", humansize(\n",
    "    (6 * num_tiles * samples_per_tile * (sample_size*sample_size) * 11 * 4) + \n",
    "    (6 * num_tiles * samples_per_tile * (sample_size*sample_size) * 18 * 4)\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make small dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset(fns, state, output_dir):\n",
    "    \n",
    "    patch_fns = []\n",
    "    patch_metadata = []\n",
    "    patch_shapes = []\n",
    "\n",
    "    for i, lc_fn in enumerate(fns):\n",
    "        print(i, len(fns))\n",
    "\n",
    "        new_naip_fn = lc_fn.replace(\"resampled-lc\", \"esri-naip\")[:-7] + \".mrf\"\n",
    "        old_naip_fn = new_to_old_map[new_naip_fn]\n",
    "        nlcd_fn = old_naip_fn.replace(\"esri-naip\", \"resampled-nlcd\")[:-4] + \"_nlcd.tif\"\n",
    "\n",
    "        naip_f = rasterio.open(new_naip_fn, \"r\")\n",
    "        crs = naip_f.crs[\"init\"]\n",
    "        naip_bounds = naip_f.bounds\n",
    "\n",
    "        lc_f = rasterio.open(lc_fn, \"r\")\n",
    "        assert lc_f.crs[\"init\"] == crs\n",
    "        lc_bounds = lc_f.bounds\n",
    "\n",
    "        nlcd_f = rasterio.open(nlcd_fn, \"r\")\n",
    "        assert nlcd_f.crs[\"init\"] == crs\n",
    "        nlcd_bounds = nlcd_f.bounds\n",
    "\n",
    "        bounds = bounds_intersection(bounds_intersection(naip_bounds, lc_bounds), nlcd_bounds)\n",
    "        left, bottom, right, top = bounds\n",
    "        geom = shapely.geometry.mapping(shapely.geometry.box(left, bottom, right, top, ccw=True))\n",
    "                \n",
    "        naip_data, _ = rasterio.mask.mask(naip_f, [geom], crop=True)\n",
    "        #naip_data = np.rollaxis(naip_data, 0, 3)\n",
    "        naip_f.close()\n",
    "        lc_data, _ = rasterio.mask.mask(lc_f, [geom], crop=True)\n",
    "        #lc_data = np.squeeze(lc_data)\n",
    "        lc_f.close()\n",
    "        nlcd_data, _ = rasterio.mask.mask(nlcd_f, [geom], crop=True)\n",
    "        #nlcd_data = np.vectorize(NLCD_CLASSES_TO_IDX.__getitem__)(nlcd_data).astype(np.uint8)\n",
    "        nlcd_f.close()\n",
    "\n",
    "        geom = fiona.transform.transform_geom(crs,'epsg:4326', geom)\n",
    "        \n",
    "        #print(naip_fn, naip_data.shape, naip_data.dtype)\n",
    "        #print(nlcd_fn, nlcd_data.shape, nlcd_data.dtype)\n",
    "        #print(lc_fn, lc_data.shape, lc_data.dtype)\n",
    "\n",
    "        _, height, width = naip_data.shape\n",
    "\n",
    "        for j in range(samples_per_tile):\n",
    "\n",
    "            y = np.random.randint(0, height-sample_size)\n",
    "            x = np.random.randint(0, width-sample_size)\n",
    "\n",
    "            merged = np.concatenate([\n",
    "                naip_data[:, y:y+sample_size, x:x+sample_size],\n",
    "                lc_data[:, y:y+sample_size, x:x+sample_size],\n",
    "                nlcd_data[:, y:y+sample_size, x:x+sample_size],\n",
    "            ])\n",
    "\n",
    "            lc_string = ','.join(map(str,get_lc_stats(merged[4,:,:])))\n",
    "            nlcd_string = ','.join(map(str,get_nlcd_stats(merged[5:,:])))\n",
    "            \n",
    "            \n",
    "            left, bottom, right, top\n",
    "            \n",
    "            t_left = left + x\n",
    "            t_right = left + x + sample_size\n",
    "            t_top = top - y\n",
    "            t_bottom = top - y - sample_size\n",
    "            t_geom = shapely.geometry.mapping(shapely.geometry.box(t_left, t_bottom, t_right, t_top, ccw=True))\n",
    "            t_geom = fiona.transform.transform_geom(crs, 'epsg:4326', t_geom)\n",
    "\n",
    "            output_fn = \"%s-%s-%d.npy\" % (\n",
    "                state,\n",
    "                os.path.basename(new_naip_fn)[:-4],\n",
    "                j\n",
    "            )\n",
    "\n",
    "            np.save(os.path.join(output_dir, output_fn), merged[np.newaxis].data)\n",
    "            patch_fns.append(os.path.join(output_dir, output_fn))\n",
    "            patch_metadata.append((\n",
    "                new_naip_fn,\n",
    "                x, y,\n",
    "                lc_string,\n",
    "                nlcd_string\n",
    "            ))\n",
    "            patch_shapes.append(json.dumps(t_geom))\n",
    "    \n",
    "    return patch_fns, patch_metadata, patch_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de_1m_2013 train\n",
      "0 25\n",
      "1 25\n",
      "2 25\n",
      "3 25\n",
      "4 25\n",
      "5 25\n",
      "6 25\n",
      "7 25\n",
      "8 25\n",
      "9 25\n",
      "10 25\n",
      "11 25\n",
      "12 25\n",
      "13 25\n",
      "14 25\n",
      "15 25\n",
      "16 25\n",
      "17 25\n",
      "18 25\n",
      "19 25\n",
      "20 25\n",
      "21 25\n",
      "22 25\n",
      "23 25\n",
      "24 25\n",
      "de_1m_2013 val\n",
      "0 5\n",
      "1 5\n",
      "2 5\n",
      "3 5\n",
      "4 5\n",
      "ny_1m_2013 train\n",
      "0 25\n",
      "1 25\n",
      "2 25\n",
      "3 25\n",
      "4 25\n",
      "5 25\n",
      "6 25\n",
      "7 25\n",
      "8 25\n",
      "9 25\n",
      "10 25\n",
      "11 25\n",
      "12 25\n",
      "13 25\n",
      "14 25\n",
      "15 25\n",
      "16 25\n",
      "17 25\n",
      "18 25\n",
      "19 25\n",
      "20 25\n",
      "21 25\n",
      "22 25\n",
      "23 25\n",
      "24 25\n",
      "ny_1m_2013 val\n",
      "0 5\n",
      "1 5\n",
      "2 5\n",
      "3 5\n",
      "4 5\n",
      "md_1m_2013 train\n",
      "0 25\n",
      "1 25\n",
      "2 25\n",
      "3 25\n",
      "4 25\n",
      "5 25\n",
      "6 25\n",
      "7 25\n",
      "8 25\n",
      "9 25\n",
      "10 25\n",
      "11 25\n",
      "12 25\n",
      "13 25\n",
      "14 25\n",
      "15 25\n",
      "16 25\n",
      "17 25\n",
      "18 25\n",
      "19 25\n",
      "20 25\n",
      "21 25\n",
      "22 25\n",
      "23 25\n",
      "24 25\n",
      "md_1m_2013 val\n",
      "0 5\n",
      "1 5\n",
      "2 5\n",
      "3 5\n",
      "4 5\n",
      "pa_1m_2013 train\n",
      "0 25\n",
      "1 25\n",
      "2 25\n",
      "3 25\n",
      "4 25\n",
      "5 25\n",
      "6 25\n",
      "7 25\n",
      "8 25\n",
      "9 25\n",
      "10 25\n",
      "11 25\n",
      "12 25\n",
      "13 25\n",
      "14 25\n",
      "15 25\n",
      "16 25\n",
      "17 25\n",
      "18 25\n",
      "19 25\n",
      "20 25\n",
      "21 25\n",
      "22 25\n",
      "23 25\n",
      "24 25\n",
      "pa_1m_2013 val\n",
      "0 5\n",
      "1 5\n",
      "2 5\n",
      "3 5\n",
      "4 5\n",
      "wv_1m_2014 train\n",
      "0 25\n",
      "1 25\n",
      "2 25\n",
      "3 25\n",
      "4 25\n",
      "5 25\n",
      "6 25\n",
      "7 25\n",
      "8 25\n",
      "9 25\n",
      "10 25\n",
      "11 25\n",
      "12 25\n",
      "13 25\n",
      "14 25\n",
      "15 25\n",
      "16 25\n",
      "17 25\n",
      "18 25\n",
      "19 25\n",
      "20 25\n",
      "21 25\n",
      "22 25\n",
      "23 25\n",
      "24 25\n",
      "wv_1m_2014 val\n",
      "0 5\n",
      "1 5\n",
      "2 5\n",
      "3 5\n",
      "4 5\n",
      "va_1m_2014 train\n",
      "0 25\n",
      "1 25\n",
      "2 25\n",
      "3 25\n",
      "4 25\n",
      "5 25\n",
      "6 25\n",
      "7 25\n",
      "8 25\n",
      "9 25\n",
      "10 25\n",
      "11 25\n",
      "12 25\n",
      "13 25\n",
      "14 25\n",
      "15 25\n",
      "16 25\n",
      "17 25\n",
      "18 25\n",
      "19 25\n",
      "20 25\n",
      "21 25\n",
      "22 25\n",
      "23 25\n",
      "24 25\n",
      "va_1m_2014 val\n",
      "0 5\n",
      "1 5\n",
      "2 5\n",
      "3 5\n",
      "4 5\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "    for ds in [\"train\", \"val\"]:\n",
    "        print(state, ds)\n",
    "        output_dir = \"/mnt/blobfuse/cnn-minibatches/cvpr_splits/%s_%s/\" % (state, ds)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        f = open(\"splits/%s_%s.txt\" % (state, ds),\"r\")\n",
    "        fns = f.read().strip().split(\"\\n\")\n",
    "        f.close()\n",
    "\n",
    "        patch_fns, patch_metadata, patch_shapes = make_dataset(fns, state, output_dir)\n",
    "        \n",
    "        f = open(\"splits/%s_%s_metadata.csv\" % (state, ds), \"w\")\n",
    "        for i in range(len(patch_fns)):\n",
    "            f.write(\"%s,%s,%d,%d,%s,%s\\n\" % (\n",
    "                patch_fns[i],\n",
    "                *patch_metadata[i]\n",
    "            ))\n",
    "        f.close()\n",
    "        \n",
    "        f = open(\"splits/%s_%s_patches.txt\" % (state, ds), \"w\")\n",
    "        f.write(\"\\n\".join(patch_fns))\n",
    "        f.close()\n",
    "        \n",
    "        f = open(\"splits/%s_%s_shapes.txt\" % (state, ds), \"w\")\n",
    "        f.write(\"\\n\".join(patch_shapes))\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make extended dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataset_big(fns, state, dataset, base_dir, output_dir):\n",
    "\n",
    "    patch_fns = []\n",
    "    patch_metadata = []\n",
    "    patch_shapes = []\n",
    "        \n",
    "    for i, lc_fn in enumerate(fns):\n",
    "        print(i, len(fns))\n",
    "\n",
    "        base_fn = \"_\".join(os.path.basename(lc_fn).split(\"_\")[:-2])\n",
    "        temp_fns = [\n",
    "            base_fn + \"_naip-new.tif\",\n",
    "            base_fn + \"_naip-old.tif\",\n",
    "            base_fn + \"_lc.tif\",\n",
    "            base_fn + \"_nlcd.tif\",\n",
    "            base_fn + \"_landsat-leaf-on.tif\",\n",
    "            base_fn + \"_landsat-leaf-off.tif\",\n",
    "            base_fn + \"_buildings.tif\",\n",
    "        ]\n",
    "        \n",
    "        input_fns = [\n",
    "            os.path.join(base_dir, \"%s_%s_tiles\" % (state, dataset), fn)\n",
    "            for fn in temp_fns\n",
    "        ]\n",
    "        \n",
    "        layer_data = []\n",
    "        left, bottom, right, top = None, None, None, None\n",
    "        crs = None\n",
    "        for fn in input_fns:\n",
    "            #print(\"Loading %s\" % (fn))\n",
    "            f = rasterio.open(fn,\"r\")\n",
    "            data = f.read()\n",
    "            left, bottom, right, top = f.bounds\n",
    "            crs = f.crs.to_string()\n",
    "            f.close()\n",
    "            layer_data.append(data)\n",
    "        \n",
    "        _, height, width = layer_data[0].shape\n",
    "\n",
    "        for j in range(samples_per_tile):\n",
    "\n",
    "            y = np.random.randint(0, height-sample_size)\n",
    "            x = np.random.randint(0, width-sample_size)\n",
    "\n",
    "            merged = np.concatenate([\n",
    "                data[:, y:y+sample_size, x:x+sample_size]\n",
    "                for data in layer_data\n",
    "            ])\n",
    "\n",
    "            lc_string = ','.join(map(str,get_lc_stats(merged[8,:,:])))\n",
    "            nlcd_string = ','.join(map(str,get_nlcd_stats(merged[9:,:])))\n",
    "            \n",
    "                        \n",
    "            t_left = left + x\n",
    "            t_right = left + x + sample_size\n",
    "            t_top = top - y\n",
    "            t_bottom = top - y - sample_size\n",
    "            t_geom = shapely.geometry.mapping(shapely.geometry.box(t_left, t_bottom, t_right, t_top, ccw=True))\n",
    "            t_geom = fiona.transform.transform_geom(crs, 'epsg:4326', t_geom)\n",
    "\n",
    "            output_fn = \"%s-%s-%d.npy\" % (\n",
    "                state,\n",
    "                base_fn,\n",
    "                j\n",
    "            )\n",
    "\n",
    "            np.save(os.path.join(output_dir, output_fn), merged[np.newaxis].data)\n",
    "            patch_fns.append(os.path.join(output_dir, output_fn))\n",
    "            patch_metadata.append((\n",
    "                base_fn,\n",
    "                x, y,\n",
    "                lc_string,\n",
    "                nlcd_string\n",
    "            ))\n",
    "            patch_shapes.append(json.dumps(t_geom))\n",
    "    \n",
    "    return patch_fns, patch_metadata, patch_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "de_1m_2013 val\n",
      "0 5\n",
      "1 5\n",
      "2 5\n",
      "3 5\n",
      "4 5\n",
      "de_1m_2013 test\n",
      "0 20\n",
      "1 20\n",
      "2 20\n",
      "3 20\n",
      "4 20\n",
      "5 20\n",
      "6 20\n",
      "7 20\n",
      "8 20\n",
      "9 20\n",
      "10 20\n",
      "11 20\n",
      "12 20\n",
      "13 20\n",
      "14 20\n",
      "15 20\n",
      "16 20\n",
      "17 20\n",
      "18 20\n",
      "19 20\n",
      "de_1m_2013 extended-train\n",
      "0 82\n",
      "1 82\n",
      "2 82\n",
      "3 82\n",
      "4 82\n",
      "5 82\n",
      "6 82\n",
      "7 82\n",
      "8 82\n",
      "9 82\n",
      "10 82\n",
      "11 82\n",
      "12 82\n",
      "13 82\n",
      "14 82\n",
      "15 82\n",
      "16 82\n",
      "17 82\n",
      "18 82\n",
      "19 82\n",
      "20 82\n",
      "21 82\n",
      "22 82\n",
      "23 82\n",
      "24 82\n",
      "25 82\n",
      "26 82\n",
      "27 82\n",
      "28 82\n",
      "29 82\n",
      "30 82\n",
      "31 82\n",
      "32 82\n",
      "33 82\n",
      "34 82\n",
      "35 82\n",
      "36 82\n",
      "37 82\n",
      "38 82\n",
      "39 82\n",
      "40 82\n",
      "41 82\n",
      "42 82\n",
      "43 82\n",
      "44 82\n",
      "45 82\n",
      "46 82\n",
      "47 82\n",
      "48 82\n",
      "49 82\n",
      "50 82\n",
      "51 82\n",
      "52 82\n",
      "53 82\n",
      "54 82\n",
      "55 82\n",
      "56 82\n",
      "57 82\n",
      "58 82\n",
      "59 82\n",
      "60 82\n",
      "61 82\n",
      "62 82\n",
      "63 82\n",
      "64 82\n",
      "65 82\n",
      "66 82\n",
      "67 82\n",
      "68 82\n",
      "69 82\n",
      "70 82\n",
      "71 82\n",
      "72 82\n",
      "73 82\n",
      "74 82\n",
      "75 82\n",
      "76 82\n",
      "77 82\n",
      "78 82\n",
      "79 82\n",
      "80 82\n",
      "81 82\n",
      "ny_1m_2013 val\n",
      "0 5\n",
      "1 5\n",
      "2 5\n",
      "3 5\n"
     ]
    }
   ],
   "source": [
    "for state in states:\n",
    "    for ds in [\"val\",\"test\",\"extended-train\"]:\n",
    "        print(state, ds)\n",
    "        extended_ds = ds if ds.startswith(\"extended\") else \"extended-%s\" % (ds)\n",
    "        \n",
    "        output_dir = \"/home/caleb/data/%s_%s_patches/\" % (state, extended_ds)\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "        f = open(\"../splits/%s_%s.txt\" % (state, ds),\"r\")\n",
    "        fns = f.read().strip().split(\"\\n\")\n",
    "        f.close()\n",
    "\n",
    "        tile_fns, patch_fns, patch_metadata, patch_shapes = make_dataset_big(\n",
    "            fns, state, extended_ds, \"/home/caleb/data/\", output_dir\n",
    "        )\n",
    "        \n",
    "        f = open(\"../splits/%s_%s_metadata.csv\" % (state, extended_ds), \"w\")\n",
    "        for i in range(len(patch_fns)):\n",
    "            f.write(\"%s,%s,%d,%d,%s,%s\\n\" % (\n",
    "                patch_fns[i],\n",
    "                *patch_metadata[i]\n",
    "            ))\n",
    "        f.close()\n",
    "        \n",
    "        f = open(\"../splits/%s_%s_patches.txt\" % (state, extended_ds), \"w\")\n",
    "        f.write(\"\\n\".join(patch_fns))\n",
    "        f.close()\n",
    "        \n",
    "        f = open(\"../splits/%s_%s_shapes.txt\" % (state, extended_ds), \"w\")\n",
    "        f.write(\"\\n\".join(patch_shapes))\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
